---
layout: post
title:  "Escalando servidor de forma simples"
date:   2024-07-15 18:30:00 +0000
categories: jekyll update
---

Quero falar sobre escalonamento de API para dar um caminho inicial por onde começar, de uma forma barata, simples, rápida e mencionar algumas ferramentas comuns que oferecem isso. E também no final, mencionar algumas dificuldades que vão aparecer após escalonarmos nossa API.

Começando, quero apresentar uma arquitetura que é comum e que é por onde começamos geralmente nossos projetos:

<img src="/assets/2024-06-24-api-arch.markdown/initial_arch.png" width="100%" />

Contextualizar cada elemneto dessa imagem:

 - Nós temos o "cliente" que pode ser uma aplicação front-end, ferramenta Postman/Insomnia ou algum outro back-end também, ou seja, alguém que vai fazer requisições para nosso back-end;

 - A "API", que será o serviço back-end que vai receber as requisições e processar o que precisa ser feito;

 - E por fim o "DB", "database" nosso banco de dados, que iremos usar para fazer uma leitura ou salvar dados.

A princípio, isso atende diversas requisições para processar mas vamos supor que o CTO da empresa chegou falando: "João, bem bacana o projeto aguentando 100 requisições simultâneas, porém nós estamos crescendo bastante e precisamos suportar 200 requisições simultaneamente", como podemos resolver isso?

# Escalando

Mas, o que é "escalar" um projeto? Vamos pensar, se uma aplicação nossa rodando aguenta 100 requisições, se tivermos duas, vamos conseguir aguentar 200 requisições? A grosso modo, é isso mesmo &#128579;! Então nossa arquitetura ficaria algo assim:

<img src="/assets/2024-06-24-api-arch.markdown/load_balancer.png" width="100%" />

Opa, agora apareceu mais alguns elementos no nosso desenho, contextualizando: 

  - NGINX, ferramenta para criar um servidor HTTP;
  - API 1, meu back-end rodando em uma porta, por exemplo, 3000;
  - API 2, meu mesmo back-end rodando em uma porta, por exemplo, 3001.

Olha que bacana, agora nós temos a mesma aplicação rodando duas vezes, agora nós podemos dobrarmos a quantidade de chamadas para o nosso serviço de 100 para 200.
Mas e o NGINX, para que ele vai servir nisso? NGINX, é um servidor HTTP e tem diversas funcionalidades como segurança, limitador de requisições, proxy reverso e o principal para nós, o balanceador de carga entre os serviços. Linguagens de programação, como PHP, Ruby, Rust, JavaScript, Java, são capazes de criar um servidor para rodar em uma porta específica porém, somente eles não conseguem escalar por conta própria, ou seja, mesmo eu tendo 2 API rodando, eles não conseguem balancear sozinho entre eles, por isso precisamos de uma ferramenta a parte. 

Agora que nós temos 2 aplicações iguais rodando em portas diferente no nosso servidor, abaixo eu mostro uma configuração simples de um projeto que fiz de exemplo com NGINX:

<img src="/assets/2024-06-24-api-arch.markdown/nginx_config.png" width="100%" />

Entendendo melhor a configuração, eu tenho dois processos em NodeJS rodando, um na porta 6001 e outro na porta 6002, eu agrupo esses meus 2 serviços em uma "upstream" chamada backend e mais abaixo, no meu "server" eu estou dizendo o seguinte: "NGINX, quando alguém acessar você, eu quero que você faça o balanceamento de carga e redirecione a requisição para um entre meus 2 processos rodando". Por padrão é utilizado o algoritmo Round Robin para o balanceamento, mas há outras estratégias, se quiser se aprofundar nisso vai ler por conta própria, <a href="https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/" target="_blank">aqui está a referência preguiçoso(a)</a>.

E dessa forma, eu consigo escalar minha aplicação a nível de requisições, porém <a href="https://github.com/JoaoWitorFelipe/simples_node_nginx_load_balancer" target="_blank">no meu projeto</a> onde eu desenvolvi esse exemplo, se formos no `package.json` é possível ver que eu preciso rodar manualmente meus 2 serviços, trazendo pra vida real e se eu precisar subir 100 serviços e balancear entre eles? É claro que não é algo viável na mão, uma forma de contornar isso é usando ferramentas como <a target="_blank" href="https://kubernetes.io/pt-br/">Kubernetes</a>, <a target="_blank" href="https://pm2.keymetrics.io/">PM2</a> ou alguma outra que combine com o NGINX para escalar a aplicação. Teríamos algo mais ao menos assim no final: 

<img src="/assets/2024-06-24-api-arch.markdown/cluster.png" width="100%" />

Com essas ferramentas, conseguimos escalar nossas aplicações automaticamente (PM2 e Kubernetes funcionam de formas diferentes, quis mostrar de uma forma mais geral) de forma rápida e também, podemos adicionar critérios comuns para fazer escalonamento automático:

 - Muitas requisições (300+ requisições, por exemplo);
 - Aumento no uso de processamento da CPU ou RAM (consumo de CPU > 80% ou consumo de RAM > 6GB, por exemplo).

Dessa forma, simples, rápida e barata ("barato", só agulha na testa mesmo &#128517;) conseguimos aumentar a perfomance da nossa aplicação, lembrando que com novas soluções, vem novos problemas, nesse último diagrama podemos ver alguns gargalos/problemas que vão surgir:
 - Banco de dados, agora com novos serviços rodando, vamos ter mais chamadas para o banco de dados, ou seja, mais leitura de dados e mais escritas, para esse tipo de situação, um escalonamento vertical já ajudaria, ou seja, aumentar a capacidade de CPU e RAM do servidor que está o banco de dados;
 - Processos em segundo plano, vamos supor que temos uma rotina que executa de hora em hora, vamos ter que nos preocupar com problemas de concorrência já que agora podemos ter serviços tentando acessar os mesmos dados no banco de dados para processar;
 - Custos, ferramentas como o Kubernetes custam valor (dinheiro mesmo) e tempo para poder configurar (não é tão simples quanto parece no diagrama hahaha);
 - E aí, que outro gargalo/problema podemos encontrar aqui?

Mas a grosso modo, esse é um desenho bem padrão de arquitetura para projetos que precisam ter um desempenho maior com mais usuários ativos. E entenda, cada problema precisa das suas próprias soluções para resolver seus problemas específicos. Tenham em mente isso sempre quando forem resolver um problema, apenas copiar e colar o que eu acabei de escrever nem sempre vai resolver tudo &#128516;.